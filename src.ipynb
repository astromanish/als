{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from monai.losses import DiceLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def dice_metric(predicted, target):\n",
    "    '''\n",
    "    In this function we take `predicted` and `target` (label) to calculate the dice coeficient then we use it \n",
    "    to calculate a metric value for the training and the validation.\n",
    "    '''\n",
    "    dice_value = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "    value = 1 - dice_value(predicted, target).item()\n",
    "    return value\n",
    "\n",
    "def calculate_weights(val1, val2):\n",
    "    '''\n",
    "    In this function we take the number of the background and the forgroud pixels to return the `weights` \n",
    "    for the cross entropy loss values.\n",
    "    '''\n",
    "    count = np.array([val1, val2])\n",
    "    summ = count.sum()\n",
    "    weights = count/summ\n",
    "    weights = 1/weights\n",
    "    summ = weights.sum()\n",
    "    weights = weights/summ\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "def train(model, data_in, loss, optim, max_epochs, model_dir, test_interval=1 , device=torch.device(\"cuda:0\")):\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    save_loss_train = []\n",
    "    save_loss_test = []\n",
    "    save_metric_train = []\n",
    "    save_metric_test = []\n",
    "    train_loader, test_loader = data_in\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        train_step = 0\n",
    "        epoch_metric_train = 0\n",
    "        for batch_data in train_loader:\n",
    "            \n",
    "            train_step += 1\n",
    "\n",
    "            volume = batch_data[\"vol\"]\n",
    "            label = batch_data[\"seg\"]\n",
    "            label = label != 0\n",
    "            volume, label = (volume.to(device), label.to(device))\n",
    "\n",
    "            optim.zero_grad()\n",
    "            outputs = model(volume)\n",
    "            \n",
    "            train_loss = loss(outputs, label)\n",
    "            \n",
    "            train_loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_epoch_loss += train_loss.item()\n",
    "            print(\n",
    "                f\"{train_step}/{len(train_loader) // train_loader.batch_size}, \"\n",
    "                f\"Train_loss: {train_loss.item():.4f}\")\n",
    "\n",
    "            train_metric = dice_metric(outputs, label)\n",
    "            epoch_metric_train += train_metric\n",
    "            print(f'Train_dice: {train_metric:.4f}')\n",
    "\n",
    "        print('-'*20)\n",
    "        \n",
    "        train_epoch_loss /= train_step\n",
    "        print(f'Epoch_loss: {train_epoch_loss:.4f}')\n",
    "        save_loss_train.append(train_epoch_loss)\n",
    "        np.save(os.path.join(model_dir, 'loss_train.npy'), save_loss_train)\n",
    "        \n",
    "        epoch_metric_train /= train_step\n",
    "        print(f'Epoch_metric: {epoch_metric_train:.4f}')\n",
    "\n",
    "        save_metric_train.append(epoch_metric_train)\n",
    "        np.save(os.path.join(model_dir, 'metric_train.npy'), save_metric_train)\n",
    "\n",
    "        if (epoch + 1) % test_interval == 0:\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_epoch_loss = 0\n",
    "                test_metric = 0\n",
    "                epoch_metric_test = 0\n",
    "                test_step = 0\n",
    "\n",
    "                for test_data in test_loader:\n",
    "\n",
    "                    test_step += 1\n",
    "\n",
    "                    test_volume = test_data[\"vol\"]\n",
    "                    test_label = test_data[\"seg\"]\n",
    "                    test_label = test_label != 0\n",
    "                    test_volume, test_label = (test_volume.to(device), test_label.to(device),)\n",
    "                    \n",
    "                    test_outputs = model(test_volume)\n",
    "                    \n",
    "                    test_loss = loss(test_outputs, test_label)\n",
    "                    test_epoch_loss += test_loss.item()\n",
    "                    test_metric = dice_metric(test_outputs, test_label)\n",
    "                    epoch_metric_test += test_metric\n",
    "                    \n",
    "                \n",
    "                test_epoch_loss /= test_step\n",
    "                print(f'test_loss_epoch: {test_epoch_loss:.4f}')\n",
    "                save_loss_test.append(test_epoch_loss)\n",
    "                np.save(os.path.join(model_dir, 'loss_test.npy'), save_loss_test)\n",
    "\n",
    "                epoch_metric_test /= test_step\n",
    "                print(f'test_dice_epoch: {epoch_metric_test:.4f}')\n",
    "                save_metric_test.append(epoch_metric_test)\n",
    "                np.save(os.path.join(model_dir, 'metric_test.npy'), save_metric_test)\n",
    "\n",
    "                if epoch_metric_test > best_metric:\n",
    "                    best_metric = epoch_metric_test\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(\n",
    "                        model_dir, \"best_metric_model.pth\"))\n",
    "                \n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {test_metric:.4f}\"\n",
    "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                    f\"at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "        f\"at epoch: {best_metric_epoch}\")\n",
    "\n",
    "\n",
    "def show_patient(data, SLICE_NUMBER=1, train=True, test=False):\n",
    "    \"\"\"\n",
    "    This function is to show one patient from your datasets, so that you can si if the it is okay or you need \n",
    "    to change/delete something.\n",
    "\n",
    "    `data`: this parameter should take the patients from the data loader, which means you need to can the function\n",
    "    prepare first and apply the transforms that you want after that pass it to this function so that you visualize \n",
    "    the patient with the transforms that you want.\n",
    "    `SLICE_NUMBER`: this parameter will take the slice number that you want to display/show\n",
    "    `train`: this parameter is to say that you want to display a patient from the training data (by default it is true)\n",
    "    `test`: this parameter is to say that you want to display a patient from the testing patients.\n",
    "    \"\"\"\n",
    "\n",
    "    check_patient_train, check_patient_test = data\n",
    "\n",
    "    view_train_patient = first(check_patient_train)\n",
    "    view_test_patient = first(check_patient_test)\n",
    "\n",
    "    \n",
    "    if train:\n",
    "        plt.figure(\"Visualization Train\", (12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"vol {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_train_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f\"seg {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_train_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n",
    "        plt.show()\n",
    "    \n",
    "    if test:\n",
    "        plt.figure(\"Visualization Test\", (12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"vol {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_test_patient[\"vol\"][0, 0, :, :, SLICE_NUMBER], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f\"seg {SLICE_NUMBER}\")\n",
    "        plt.imshow(view_test_patient[\"seg\"][0, 0, :, :, SLICE_NUMBER])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def calculate_pixels(data):\n",
    "    val = np.zeros((1, 2))\n",
    "\n",
    "    for batch in tqdm(data):\n",
    "        batch_label = batch[\"seg\"] != 0\n",
    "        _, count = np.unique(batch_label, return_counts=True)\n",
    "\n",
    "        if len(count) == 1:\n",
    "            count = np.append(count, 0)\n",
    "        val += count\n",
    "\n",
    "    print('The last values:', val)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import dicom2nifti\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    ")\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "\"\"\"\n",
    "This file is for preporcessing only, it contains all the functions that you need\n",
    "to make your data ready for training.\n",
    "\n",
    "You need to install the required libraries if you do not already have them.\n",
    "\n",
    "pip install os, ...\n",
    "\"\"\"\n",
    "\n",
    "def create_groups(in_dir, out_dir, Number_slices):\n",
    "    '''\n",
    "    This function is to get the last part of the path so that we can use it to name the folder.\n",
    "    `in_dir`: the path to your folders that contain dicom files\n",
    "    `out_dir`: the path where you want to put the converted nifti files\n",
    "    `Number_slices`: here you put the number of slices that you need for your project and it will \n",
    "    create groups with this number.\n",
    "    '''\n",
    "\n",
    "    for patient in glob(in_dir + '/*'):\n",
    "        patient_name = os.path.basename(os.path.normpath(patient))\n",
    "\n",
    "        # Here we need to calculate the number of folders which mean into how many groups we will divide the number of slices\n",
    "        number_folders = int(len(glob(patient + '/*')) / Number_slices)\n",
    "\n",
    "        for i in range(number_folders):\n",
    "            output_path = os.path.join(out_dir, patient_name + '_' + str(i))\n",
    "            os.mkdir(output_path)\n",
    "\n",
    "            # Move the slices into a specific folder so that you will save memory in your desk\n",
    "            for i, file in enumerate(glob(patient + '/*')):\n",
    "                if i == Number_slices + 1:\n",
    "                    break\n",
    "                \n",
    "                shutil.move(file, output_path)\n",
    "\n",
    "\n",
    "def dcm2nifti(in_dir, out_dir):\n",
    "    '''\n",
    "    This function will be used to convert dicoms into nifti files after creating the groups with \n",
    "    the number of slices that you want.\n",
    "    `in_dir`: the path to the folder where you have all the patients (folder of all the groups).\n",
    "    `out_dir`: the path to the output, which means where you want to save the converted nifties.\n",
    "    '''\n",
    "\n",
    "    for folder in tqdm(glob(in_dir + '/*')):\n",
    "        patient_name = os.path.basename(os.path.normpath(folder))\n",
    "        dicom2nifti.dicom_series_to_nifti(folder, os.path.join(out_dir, patient_name + '.nii.gz'))\n",
    "\n",
    "\n",
    "def find_empy(in_dir):\n",
    "    '''\n",
    "    This function will help you to find the empty volumes that you may not need for your training\n",
    "    so instead of opening all the files and search for the empty ones, them use this function to make it quick.\n",
    "    '''\n",
    "    \n",
    "    list_patients = []\n",
    "    for patient in glob(os.path.join(in_dir, '*')):\n",
    "        img = nib.load(patient)\n",
    "\n",
    "        if len(np.unique(img.get_fdata())) > 2:\n",
    "            print(os.path.basename(os.path.normpath(patient)))\n",
    "            list_patients.append(os.path.basename(os.path.normpath(patient)))\n",
    "    \n",
    "    return list_patients\n",
    "\n",
    "\n",
    "def prepare(in_dir, pixdim=(1.5, 1.5, 1.0), a_min=-200, a_max=200, spatial_size=[128,128,64], cache=False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function is for preprocessing, it contains only the basic transforms, but you can add more operations that you \n",
    "    find in the Monai documentation.\n",
    "    https://monai.io/docs.html\n",
    "    \"\"\"\n",
    "\n",
    "    set_determinism(seed=0)\n",
    "\n",
    "    path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
    "    path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "    path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
    "    path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "    train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "    test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
    "\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=[\"vol\", \"seg\"], source_key=\"vol\"),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "            AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "            Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
    "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "            ScaleIntensityRanged(keys=[\"vol\"], a_min=a_min, a_max=a_max,b_min=0.0, b_max=1.0, clip=True), \n",
    "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "            Resized(keys=[\"vol\", \"seg\"], spatial_size=spatial_size),   \n",
    "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if cache:\n",
    "        train_ds = CacheDataset(data=train_files, transform=train_transforms,cache_rate=1.0)\n",
    "        train_loader = DataLoader(train_ds, batch_size=1)\n",
    "\n",
    "        test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
    "        test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    else:\n",
    "        train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "        train_loader = DataLoader(train_ds, batch_size=1)\n",
    "\n",
    "        test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "        test_loader = DataLoader(test_ds, batch_size=1)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss, DiceCELoss\n",
    "\n",
    "import torch\n",
    "from src.preporcess import prepare\n",
    "from src.utilities import train\n",
    "\n",
    "\n",
    "data_dir = 'D:/Youtube/Organ and Tumor Segmentation/datasets/Task03_Liver/Data_Train_Test'\n",
    "model_dir = 'D:/Youtube/Organ and Tumor Segmentation/results/results' \n",
    "data_in = prepare(data_dir, cache=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "#loss_function = DiceCELoss(to_onehot_y=True, sigmoid=True, squared_pred=True, ce_weight=calculate_weights(1792651250,2510860).to(device))\n",
    "loss_function = DiceLoss(to_onehot_y=True, sigmoid=True, squared_pred=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5, weight_decay=1e-5, amsgrad=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train(model, data_in, loss_function, optimizer, 600, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import(\n",
    "    Compose,\n",
    "    AddChanneld,\n",
    "    LoadImaged,\n",
    "    Resized,\n",
    "    ToTensord,\n",
    "    Spacingd,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'D:/Youtube/Organ and Tumor Segmentation/datasets/Task03_Liver/Data_Train_Test'\n",
    "model_dir = 'D:/Youtube/Organ and Tumor Segmentation/results/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
    "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
    "test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
    "test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Results 25 june\", (12, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Train dice loss\")\n",
    "x = [i + 1 for i in range(len(train_loss))]\n",
    "y = train_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Train metric DICE\")\n",
    "x = [i + 1 for i in range(len(train_metric))]\n",
    "y = train_metric\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Test dice loss\")\n",
    "x = [i + 1 for i in range(len(test_loss))]\n",
    "y = test_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Test metric DICE\")\n",
    "x = [i + 1 for i in range(len(test_metric))]\n",
    "y = test_metric\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
    "path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
    "path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
    "test_files = test_files[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
    "        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
    "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw_batch_size = 4\n",
    "roi_size = (128, 128, 64)\n",
    "with torch.no_grad():\n",
    "    test_patient = first(test_loader)\n",
    "    t_volume = test_patient['vol']\n",
    "    #t_segmentation = test_patient['seg']\n",
    "    \n",
    "    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
    "    sigmoid_activation = Activations(sigmoid=True)\n",
    "    test_outputs = sigmoid_activation(test_outputs)\n",
    "    test_outputs = test_outputs > 0.53\n",
    "        \n",
    "    for i in range(32):\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af407973ba12897262deda9d8992946cc1a9873fff2de40f1acc89cdf9010052"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
